{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7f5cef-f3f5-4422-bf83-078d715980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b23a61-7e9a-44a5-96da-a88a91600da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_length:int, d_model:int, n = 10000, dtype = torch.float32):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.d_model = d_model\n",
    "        self.n = n\n",
    "        self.dtype = dtype\n",
    "        self.encode_table = nn.Parameter(self._create_table())\n",
    "\n",
    "    def _create_table(self) -> torch.tensor:\n",
    "        table = torch.zeros((self.seq_length, self.d_model),dtype=self.dtype)\n",
    "\n",
    "        for pos in torch.arange(self.seq_length):\n",
    "            # Here d_model is divide by 2 because the 2*i and 2*i + 1\n",
    "            # The interaction foward two by two \n",
    "            for i in torch.arange(self.d_model//2):\n",
    "                denominator = 2*i/self.d_model\n",
    "                calculation = pos/torch.pow(self.n, denominator)\n",
    "                table[pos,2*i]      = torch.sin(calculation) \n",
    "                table[pos,2*i + 1]  = torch.cos(calculation)\n",
    "\n",
    "        return table\n",
    "\n",
    "    def forward(self,x:torch.tensor) -> torch.tensor:\n",
    "        x += self.encode_table\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e80408a-807e-427e-9522-dab21ba38351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query:torch.tensor, key:torch.tensor, value:torch.tensor) -> [torch.tensor,torch.tensor]:\n",
    "    factor = 1/torch.sqrt(torch.tensor(key.size(-1)))\n",
    "    attn = F.softmax(torch.matmul(query,key.transpose(-2,-1))*factor,dim=-1)\n",
    "\n",
    "    x = torch.matmul(attn,value)\n",
    "\n",
    "    return x, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cc56bf-4b10-4cc0-8188-aaca745efced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, d_model:int, d_k:int, d_v:int):\n",
    "        super(HeadAttention,self).__init__()\n",
    "        self.weights_query = nn.Parameter(torch.randn(d_model,d_k))\n",
    "        self.weights_key = nn.Parameter(torch.randn(d_model,d_k))\n",
    "        self.weights_value = nn.Parameter(torch.randn(d_model,d_v))\n",
    "\n",
    "    def forward(self, query:torch.tensor, key:torch.tensor, value:torch.tensor) -> torch.tensor:\n",
    "        q = torch.matmul(query,self.weights_query)\n",
    "        k = torch.matmul(key,self.weights_key)\n",
    "        v = torch.matmul(value,self.weights_value)\n",
    "\n",
    "        x, _ = scaled_dot_product_attention(q,k,v)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b7211d-3c55-4521-ba21-02966d9853eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, d_model:int, d_k:int, d_v:int, h:int):\n",
    "        super(MultiHead,self).__init__()\n",
    "        self.weights_concat = nn.Parameter(torch.randn(d_v*h,d_model))\n",
    "\n",
    "        self.multi_head = nn.ModuleList([\n",
    "            HeadAttention(d_model=d_model, d_k=d_k, d_v=d_v) for _ in range(h)\n",
    "        ])\n",
    "\n",
    "        self.norm_layer = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, query:torch.tensor, key:torch.tensor, value:torch.tensor) -> torch.tensor:\n",
    "        x = torch.concat([module_(query, key, value) for module_ in self.multi_head],dim=-1)\n",
    "        x = torch.matmul(x,self.weights_concat)\n",
    "\n",
    "        x += query\n",
    "\n",
    "        x = self.norm_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64986463-ba99-4549-bce7-d4c88c9333fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForwardNetworks(nn.Module):\n",
    "    def __init__(self, d_model:int, d_ff:int):\n",
    "        super(PositionWiseFeedForwardNetworks,self).__init__()\n",
    "        self.linear_inner_layer = nn.Linear(d_model,d_ff)\n",
    "        self.linear_layer = nn.Linear(d_ff,d_model)\n",
    "\n",
    "        self.norm_layer = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x:torch.tensor) -> torch.tensor:\n",
    "        x = self.linear_inner_layer(x)\n",
    "        x = x.relu()\n",
    "        x = self.linear_layer(x)\n",
    "\n",
    "        x += x\n",
    "        x = self.norm_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d236360-6458-4bfb-a07f-1d065fc0e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model:int, d_k:int, d_v:int, h:int, d_ff:int):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.multi_head_attention = MultiHead(d_model=d_model,d_k=d_k,d_v=d_v,h=h)\n",
    "        self.position_wise_feed_forward_networks = PositionWiseFeedForwardNetworks(d_model=d_model,d_ff=d_ff)\n",
    "\n",
    "    def forward(self, query:torch.tensor, key:torch.tensor, value:torch.tensor) -> torch.tensor:\n",
    "        x = self.multi_head_attention(query=value, key=key, value=value)\n",
    "        x = self.position_wise_feed_forward_networks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3f6db9-1d05-4be8-9b70-ae27d35c1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_length: int, n_layers:int, d_model:int, d_k:int, d_v:int, h:int, d_ff:int):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(seq_length=seq_length,d_model=d_model)\n",
    "        self.encoder_layer = nn.ModuleList([\n",
    "            EncoderLayer(d_model=d_model,d_k=d_k,d_v=d_v,h=h,d_ff=d_ff) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src:torch.tensor) -> torch.tensor:\n",
    "        src = self.positional_encoding(src)\n",
    "        for module_ in self.encoder_layer:\n",
    "            src += module_(src,src,src)\n",
    "\n",
    "        return src\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713e4b58-5548-4c07-903f-697282299a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7a6346-dc17-4be0-ac81-686a26006c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "Encoder                                                 [64, 725, 512]            --\n",
       "├─PositionalEncoding: 1-1                               [64, 725, 512]            371,200\n",
       "├─ModuleList: 1-2                                       --                        --\n",
       "│    └─EncoderLayer: 2-1                                [64, 725, 512]            --\n",
       "│    │    └─MultiHead: 3-1                              [64, 725, 512]            525,312\n",
       "│    │    └─PositionWiseFeedForwardNetworks: 3-2        [64, 725, 512]            2,100,736\n",
       "│    └─EncoderLayer: 2-2                                [64, 725, 512]            --\n",
       "│    │    └─MultiHead: 3-3                              [64, 725, 512]            525,312\n",
       "│    │    └─PositionWiseFeedForwardNetworks: 3-4        [64, 725, 512]            2,100,736\n",
       "│    └─EncoderLayer: 2-3                                [64, 725, 512]            --\n",
       "│    │    └─MultiHead: 3-5                              [64, 725, 512]            525,312\n",
       "│    │    └─PositionWiseFeedForwardNetworks: 3-6        [64, 725, 512]            2,100,736\n",
       "│    └─EncoderLayer: 2-4                                [64, 725, 512]            --\n",
       "│    │    └─MultiHead: 3-7                              [64, 725, 512]            525,312\n",
       "│    │    └─PositionWiseFeedForwardNetworks: 3-8        [64, 725, 512]            2,100,736\n",
       "=========================================================================================================\n",
       "Total params: 10,875,392\n",
       "Trainable params: 10,875,392\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 73.52\n",
       "=========================================================================================================\n",
       "Input size (MB): 95.03\n",
       "Forward/backward pass size (MB): 5891.69\n",
       "Params size (MB): 41.40\n",
       "Estimated Total Size (MB): 6028.12\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder, input_size=(64, 725, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3ff46-3320-4eee-8a9d-a21b0b33fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d2c727-6e2c-4618-9779-9884b5f5d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(725,4,512,64,64,4,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ec2eb5-5982-4044-8747-6d338405c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50518658-cee8-436b-9756-fb613a3da38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(64,725,512).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a3ed5-3c56-4538-93fa-e4871cd23c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b47cd-ba8e-4df1-9979-5a3c5db7e7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
